# ğŸ¬ ClipWeaver

> **AI Storyboarder for AI Videos**  
> Helping creators turn fragmented AI-generated clips into cohesive stories.

---

## ğŸš€ Overview

**ClipWeaver** is an AI-assisted video composition tool that bridges the gap between **AI video generation** (like Pika, Runway, or Veo) and **actual storytelling**.

Instead of generating new clips, ClipWeaver **analyzes**, **organizes**, and **weaves** existing clips into structured narratives. It detects scenes, describes them with AI, and generates storyboards or even final composite videos.

This project was prototyped during **#SFTechWeek â€” [Vibe Space Hackathon](https://partiful.com/e/DHxYqtnTfGg5O0IXn5L4)** as a 2-hour demo, and is now expanding into a full-featured AI storytelling framework.

---

## ğŸŒŸ Motto

> **My app ClipWeaver is an AI-assisted video composer that helps creators turn short AI-generated clips into cohesive stories using automated scene analysis, narrative structuring, and smart editing guidance.**

---

## ğŸ§© Problem

AI video tools like **Pika**, **Runway**, or **Veo** are incredible â€” but they leave you with **dozens of disconnected 3â€“8 second clips**.  
Turning those into a meaningful video story still takes hours of manual editing.

---

## ğŸ’¡ Solution

ClipWeaver automates post-generation storytelling in four steps:

1. **Analyze Clips** â€” detect scenes, extract screenshots, transcribe voice (if any).
2. **Describe in Markdown** â€” summarize each scene with AI-generated text and image previews.
3. **Generate Scenario JSON** â€” define sequence, transitions, and optional audio plan.
4. **Compose Final Video** â€” use `ffmpeg` or compatible editor to merge chosen parts.

---

## ğŸ§  Secret Sauce

Unlike AI video generators, ClipWeaver doesnâ€™t make new content.  
It **understands** and **curates** whatâ€™s already generated â€” turning chaos into story structure.

---

## ğŸ§± Tech Stack

| Component | Description | Tools |
|------------|--------------|--------|
| **Backend** | Scene detection, AI captioning | Python, Flask, ffmpeg, OpenAI API |
| **Frontend** | Upload, display storyboard | Bolt.new (React/Next.js) |
| **Optional Server** | For video composition | Ubuntu + Docker |
| **AI** | Scene understanding & text generation | GPT-4/5 (vision mode) |
| **File Format** | Scene catalog | Markdown + JSON |

---

## âš¡ Hackathon MVP: *ClipWeaver Lite*

A 2-hour demo built for **[Vibe Space](https://partiful.com/e/DHxYqtnTfGg5O0IXn5L4) @ #SFTechWeek**  
> â€œFrom raw clip to AI-generated storyboard â€” in one click.â€

### ğŸ¯ MVP Goals
- Upload a short video
- Auto-detect scene cuts with `ffmpeg`
- Generate keyframe thumbnails
- Use GPT to describe each scene
- Export to a readable Markdown storyboard

### ğŸ§© Features Implemented
âœ… Scene detection  
âœ… Screenshot extraction  
âœ… AI text description  
âœ… Markdown export  
âœ… Simple Bolt.new UI  

### ğŸ–¥ï¸ Folder Structure
```
clipweaver-lite/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ analyzer.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ output/
â”‚       â”œâ”€â”€ scenes/
â”‚       â””â”€â”€ storyboard.md
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ (Bolt.new project)
â””â”€â”€ sample.mp4
```

### ğŸ› ï¸ Setup Instructions

#### Backend
```bash
cd backend
pip install -r requirements.txt
sudo apt install ffmpeg
export OPENAI_API_KEY="your_key_here"
python app.py

Frontend (Bolt.new)
	â€¢	Create a new Bolt project.
	â€¢	Use the provided App.jsx snippet to connect to the backend.
	â€¢	Upload a video â†’ click Analyze Video â†’ view generated Markdown.

â¸»

ğŸ§© Example Output

Input: sample.mp4 (10-second AI-generated clip)
Output: storyboard.md

# Storyboard

## Scene 1
![Scene 1](scene_001.png)
- Description: A person walks through a neon-lit alley, camera slowly pans left.

## Scene 2
![Scene 2](scene_002.png)
- Description: The same character stops under a flickering sign, looking up as rain starts to fall.


â¸»

ğŸŒ Full Project Vision

ClipWeaver (Full Version) is a modular platform that takes multiple clips, catalogs them into structured Markdown, and then automatically builds cohesive stories with optional narration and soundtrack.

ğŸ§© Full Workflow

Step	Description	Output
1ï¸âƒ£	Scene Analysis	Markdown with image + transcript
2ï¸âƒ£	Scenario Generation	JSON defining clip order, timing, audio
3ï¸âƒ£	Storyboard Visualization	Interactive editor in web UI
4ï¸âƒ£	Final Composition	Rendered .mp4 video assembled via ffmpeg


â¸»

ğŸ§© Future Roadmap

Phase	Feature	Status
MVP	Scene detection + Markdown output	âœ… Done
v0.2	Whisper-based voice transcription	ğŸ•“ Planned
v0.3	JSON-based scenario editor	ğŸ•“ Planned
v0.4	FFMPEG-based final video generation	ğŸ•“ Planned
v1.0	Full AI-assisted story composer (public launch)	ğŸ”œ Coming soon


â¸»

ğŸ§  Potential Integrations
	â€¢	Input sources: Runway, Pika, Veo, Kling, YouTube shorts
	â€¢	Output targets: CapCut, DaVinci Resolve, Premiere Pro XML
	â€¢	Plugins: â€œSend to ClipWeaverâ€ browser extension

â¸»

ğŸ¯ Elevator Pitch

â€œWe built ClipWeaver, an AI-assisted video composer that helps creators turn fragmented AI-generated clips into cohesive stories.
Instead of making new videos, ClipWeaver understands and organizes what you already have â€” automatically detecting scenes, describing them, and building storyboards you can actually use.â€

â¸»

ğŸ§­ Motto (Short Version)

ClipWeaver â€” the AI Storyboarder for AI Videos.

â¸»

ğŸ‘¤ Authors

Denis Bystruev, Valerii Egorov
Built during #SFTechWeek â€” [Vibe Space Hackathon](https://partiful.com/e/DHxYqtnTfGg5O0IXn5L4)
Location: Frontier Tower, San Francisco
Date: October 7, 2025

â¸»

ğŸ“œ License

MIT License Â© 2025 Denis Bystruev, Valerii Egorov
Youâ€™re free to fork, remix, or integrate this idea into your AI video tools.